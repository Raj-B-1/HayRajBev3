{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real vs Fake Image Detector - Using ProGAN Dataset\n",
    "\n",
    "This notebook trains a ResNet-50 model to detect fake images using the properly organized ProGAN dataset.\n",
    "\n",
    "**Dataset Structure:**\n",
    "```\n",
    "/scratch/rzc7ew/progan/\n",
    "├── airplane/0_real/  (real images)\n",
    "├── airplane/1_fake/  (ProGAN-generated fakes)\n",
    "├── bicycle/0_real/\n",
    "├── bicycle/1_fake/\n",
    "└── ... (all categories)\n",
    "```\n",
    "\n",
    "**Training:**\n",
    "- **Real (Class 0)**: All images from `*/0_real/` folders\n",
    "- **Fake (Class 1)**: All images from `*/1_fake/` folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASET_ROOT = '/scratch/rzc7ew/progan'  # Can change to biggan, stylegan, etc.\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 20\n",
    "PATIENCE = 5\n",
    "BLUR_PROB = 0.5\n",
    "JPEG_PROB = 0.5\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Dataset: {DATASET_ROOT}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_curve, average_precision_score,\n",
    "    roc_auc_score, roc_curve, classification_report, confusion_matrix\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATASET_ROOT):\n",
    "    print(f\"❌ ERROR: Dataset not found at: {DATASET_ROOT}\")\n",
    "else:\n",
    "    print(f\"✓ Dataset directory found: {DATASET_ROOT}\")\n",
    "    print(\"\\nCategories available:\")\n",
    "    categories = [d for d in os.listdir(DATASET_ROOT) \n",
    "                  if os.path.isdir(os.path.join(DATASET_ROOT, d))]\n",
    "    for i, cat in enumerate(categories[:10], 1):\n",
    "        print(f\"  {i}. {cat}\")\n",
    "    if len(categories) > 10:\n",
    "        print(f\"  ... and {len(categories) - 10} more categories\")\n",
    "    print(f\"\\nTotal categories: {len(categories)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation:\n",
    "    \"\"\"Data augmentation from CNNDetection paper\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def apply_gaussian_blur(img, sigma_range=(0.0, 3.0)):\n",
    "        sigma = np.random.uniform(sigma_range[0], sigma_range[1])\n",
    "        if sigma > 0:\n",
    "            img_array = np.array(img)\n",
    "            for i in range(3):\n",
    "                img_array[:, :, i] = gaussian_filter(img_array[:, :, i], sigma=sigma)\n",
    "            return Image.fromarray(img_array)\n",
    "        return img\n",
    "    \n",
    "    @staticmethod\n",
    "    def apply_jpeg_compression(img, quality_range=(30, 100)):\n",
    "        quality = np.random.randint(quality_range[0], quality_range[1] + 1)\n",
    "        buffer = BytesIO()\n",
    "        img.save(buffer, format='JPEG', quality=quality)\n",
    "        buffer.seek(0)\n",
    "        return Image.open(buffer)\n",
    "    \n",
    "    @staticmethod\n",
    "    def augment(img, blur_prob=0.5, jpeg_prob=0.5):\n",
    "        if random.random() < blur_prob:\n",
    "            img = DataAugmentation.apply_gaussian_blur(img)\n",
    "        if random.random() < jpeg_prob:\n",
    "            img = DataAugmentation.apply_jpeg_compression(img)\n",
    "        return img\n",
    "\n",
    "print(\"✓ Data augmentation defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealFakeDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None, augment=True,\n",
    "                 blur_prob=0.5, jpeg_prob=0.5):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "        self.blur_prob = blur_prob\n",
    "        self.jpeg_prob = jpeg_prob\n",
    "        \n",
    "        print(f\"Dataset: {len(self.image_paths)} images\")\n",
    "        print(f\"  - Real: {sum(1 for l in self.labels if l == 0)}\")\n",
    "        print(f\"  - Fake: {sum(1 for l in self.labels if l == 1)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            img = Image.new('RGB', (224, 224))\n",
    "        \n",
    "        if self.augment:\n",
    "            img = DataAugmentation.augment(img, self.blur_prob, self.jpeg_prob)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "print(\"✓ Dataset class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Load Real and Fake Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_fake_data(dataset_root):\n",
    "    \"\"\"Load real (0_real) and fake (1_fake) images from organized dataset\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"Loading Real and Fake Images\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    real_images = []\n",
    "    fake_images = []\n",
    "    \n",
    "    # Scan all category folders\n",
    "    categories = [d for d in os.listdir(dataset_root) \n",
    "                  if os.path.isdir(os.path.join(dataset_root, d))]\n",
    "    \n",
    "    print(f\"\\nScanning {len(categories)} categories...\")\n",
    "    \n",
    "    for category in tqdm(categories, desc=\"Loading categories\"):\n",
    "        category_path = os.path.join(dataset_root, category)\n",
    "        \n",
    "        # Load real images (0_real folder)\n",
    "        real_folder = os.path.join(category_path, '0_real')\n",
    "        if os.path.exists(real_folder):\n",
    "            for file in os.listdir(real_folder):\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                    real_images.append(os.path.join(real_folder, file))\n",
    "        \n",
    "        # Load fake images (1_fake folder)\n",
    "        fake_folder = os.path.join(category_path, '1_fake')\n",
    "        if os.path.exists(fake_folder):\n",
    "            for file in os.listdir(fake_folder):\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                    fake_images.append(os.path.join(fake_folder, file))\n",
    "    \n",
    "    print(f\"\\n✓ Found {len(real_images)} real images\")\n",
    "    print(f\"✓ Found {len(fake_images)} fake images\")\n",
    "    \n",
    "    if len(real_images) == 0 or len(fake_images) == 0:\n",
    "        print(\"\\n❌ ERROR: Not enough images!\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Balance dataset\n",
    "    min_count = min(len(real_images), len(fake_images))\n",
    "    print(f\"\\nBalancing to {min_count} images per class\")\n",
    "    \n",
    "    real_images = random.sample(real_images, min_count)\n",
    "    fake_images = random.sample(fake_images, min_count)\n",
    "    \n",
    "    # Create labels\n",
    "    real_labels = [0] * len(real_images)\n",
    "    fake_labels = [1] * len(fake_images)\n",
    "    \n",
    "    # Combine and shuffle\n",
    "    all_images = real_images + fake_images\n",
    "    all_labels = real_labels + fake_labels\n",
    "    \n",
    "    combined = list(zip(all_images, all_labels))\n",
    "    random.shuffle(combined)\n",
    "    all_images, all_labels = zip(*combined)\n",
    "    all_images = list(all_images)\n",
    "    all_labels = list(all_labels)\n",
    "    \n",
    "    # 80/20 split\n",
    "    split_idx = int(0.8 * len(all_images))\n",
    "    \n",
    "    train_images = all_images[:split_idx]\n",
    "    train_labels = all_labels[:split_idx]\n",
    "    val_images = all_images[split_idx:]\n",
    "    val_labels = all_labels[split_idx:]\n",
    "    \n",
    "    print(f\"\\nFinal split:\")\n",
    "    print(f\"  Training: {len(train_images)} images\")\n",
    "    print(f\"    - Real: {sum(1 for l in train_labels if l == 0)}\")\n",
    "    print(f\"    - Fake: {sum(1 for l in train_labels if l == 1)}\")\n",
    "    print(f\"  Validation: {len(val_images)} images\")\n",
    "    print(f\"    - Real: {sum(1 for l in val_labels if l == 0)}\")\n",
    "    print(f\"    - Fake: {sum(1 for l in val_labels if l == 1)}\")\n",
    "    \n",
    "    return train_images, train_labels, val_images, val_labels\n",
    "\n",
    "# Load data\n",
    "train_images, train_labels, val_images, val_labels = load_real_fake_data(DATASET_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Define Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"✓ Transforms defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RealFakeDataset(\n",
    "    train_images, train_labels,\n",
    "    transform=train_transform,\n",
    "    augment=True,\n",
    "    blur_prob=BLUR_PROB,\n",
    "    jpeg_prob=JPEG_PROB\n",
    ")\n",
    "\n",
    "val_dataset = RealFakeDataset(\n",
    "    val_images, val_labels,\n",
    "    transform=val_transform,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ DataLoaders:\")\n",
    "print(f\"  - Training batches: {len(train_loader)}\")\n",
    "print(f\"  - Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeImageDetector(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(FakeImageDetector, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=pretrained)\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "model = FakeImageDetector(pretrained=True).to(device)\n",
    "print(f\"✓ Model: {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999))\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.1, patience=3\n",
    ")\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_acc': [],\n",
    "    'val_ap': []\n",
    "}\n",
    "\n",
    "print(\"✓ Training setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).view(-1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validation'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            outputs = model(images).view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).float()\n",
    "            \n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_ap = average_precision_score(all_labels, all_probs)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, epoch_ap, all_probs, all_labels\n",
    "\n",
    "print(\"✓ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Starting Training: Real vs Fake Detection\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, val_ap, _, _ = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_ap'].append(val_ap)\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val AP: {val_ap:.4f}\")\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_ap': val_ap\n",
    "        }, 'best_model_real_vs_fake.pth')\n",
    "        print(f\"  >>> Best model saved! (Val Acc: {val_acc:.4f})\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"\\nEarly stopping after {epoch + 1} epochs\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Training Complete!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps 13-16: Evaluation, Visualization, Confusion Matrix\n",
    "\n",
    "*Use the same evaluation code from previous notebooks*\n",
    "\n",
    "**Expected Results:**\n",
    "- Accuracy: **80-95%** (real images vs GAN-generated)\n",
    "- Much better than synthetic approach\n",
    "- Proper real vs fake detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
